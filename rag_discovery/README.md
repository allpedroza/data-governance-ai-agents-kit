# ğŸ” Data Discovery RAG Agent

Sistema de IA para **descoberta de dados** usando **RAG (Retrieval-Augmented Generation)** com banco vetorizado. Permite busca semÃ¢ntica em metadados de data lakes usando linguagem natural.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [CaracterÃ­sticas](#caracterÃ­sticas)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Guia RÃ¡pido](#guia-rÃ¡pido)
- [Casos de Uso](#casos-de-uso)
- [Exemplos](#exemplos)
- [Arquitetura](#arquitetura)
- [IntegraÃ§Ã£o com Apache Atlas](#integraÃ§Ã£o-com-apache-atlas)
- [IntegraÃ§Ã£o com Data Lineage Agent](#integraÃ§Ã£o-com-data-lineage-agent)
- [API Reference](#api-reference)
- [FAQ](#faq)

## ğŸ¯ VisÃ£o Geral

O **Data Discovery RAG Agent** resolve o problema de **descoberta de dados** em data lakes complexos. Usando tÃ©cnicas de RAG (Retrieval-Augmented Generation), o agente:

1. **Indexa metadados** de tabelas em um banco vetorizado (ChromaDB)
2. Permite **busca semÃ¢ntica** usando linguagem natural
3. **Responde perguntas** sobre os dados com contexto completo
4. **Integra** com ferramentas de catÃ¡logo como Apache Atlas
5. **Combina** com anÃ¡lise de linhagem para governanÃ§a completa

### Por que usar RAG para descoberta de dados?

- âœ… **Busca natural**: "Onde estÃ£o os dados de clientes?" ao invÃ©s de queries SQL complexas
- âœ… **Contextual**: Entende sinÃ´nimos, conceitos relacionados e intenÃ§Ã£o
- âœ… **EscalÃ¡vel**: Funciona com milhares de tabelas
- âœ… **Inteligente**: Usa LLM para explicar e recomendar datasets

## âœ¨ CaracterÃ­sticas

### Core Features

- ğŸ” **Busca SemÃ¢ntica**: Encontre tabelas usando linguagem natural
- ğŸ¤– **RAG Completo**: Perguntas e respostas com contexto de metadados
- ğŸ’¾ **Banco Vetorizado**: ChromaDB para embedding storage eficiente
- ğŸ“Š **Metadados Ricos**: Suporta colunas, tags, descriÃ§Ãµes, estatÃ­sticas
- ğŸ”„ **IntegraÃ§Ã£o Atlas**: Importa metadados do Apache Atlas
- ğŸŒ **Multi-formato**: Suporta Parquet, Delta, CSV, etc.

### Funcionalidades AvanÃ§adas

- ğŸ¯ **Relevance Scoring**: Ranking inteligente de resultados
- ğŸ·ï¸ **Tag-based Filtering**: Filtre por PII, critical, etc.
- ğŸ“ˆ **EstatÃ­sticas**: Insights sobre o catÃ¡logo indexado
- ğŸ’¾ **Export/Import**: Backup e portabilidade de metadados
- ğŸ”— **Lineage Integration**: Combine com anÃ¡lise de linhagem

## ğŸ“¦ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8+
- Chave de API da OpenAI (para embeddings e LLM)

### InstalaÃ§Ã£o bÃ¡sica

```bash
# Clone o repositÃ³rio
git clone <repo-url>
cd data-governance-ai-agents-kit/rag_discovery

# Instale as dependÃªncias
pip install -r requirements.txt

# Configure a API key da OpenAI
export OPENAI_API_KEY="sua-chave-aqui"

# Opcional: configure URL customizada (ex: Azure OpenAI)
export OPENAI_API_URL="https://api.openai.com/v1"
```

### InstalaÃ§Ã£o com Docker

```bash
docker build -t data-discovery-rag .
docker run -e OPENAI_API_KEY=$OPENAI_API_KEY data-discovery-rag
```

## ğŸš€ Guia RÃ¡pido

### 1. Inicializar o Agente

```python
from data_discovery_rag_agent import DataDiscoveryRAGAgent

# Inicializa o agente
agent = DataDiscoveryRAGAgent(
    collection_name="my_data_lake",
    persist_directory="./chroma_db"
)
```

### 2. Indexar Metadados

```python
from data_discovery_rag_agent import TableMetadata

# Cria metadados de uma tabela
table = TableMetadata(
    name="customers",
    database="production",
    schema="public",
    description="Tabela de clientes com dados cadastrais",
    columns=[
        {"name": "id", "type": "bigint", "description": "ID Ãºnico"},
        {"name": "name", "type": "varchar", "description": "Nome do cliente"},
        {"name": "email", "type": "varchar", "description": "Email"}
    ],
    owner="data-team",
    tags=["pii", "critical"],
    location="s3://lake/customers/",
    format="delta"
)

# Indexa a tabela
agent.index_table(table)
```

### 3. Buscar Tabelas

```python
# Busca usando linguagem natural
results = agent.search("Onde estÃ£o os dados de clientes?", n_results=5)

for result in results:
    print(f"{result.table.name}: {result.relevance_score:.1%}")
    print(f"  {result.table.description}")
```

### 4. Fazer Perguntas

```python
# Pergunta com RAG completo (LLM + busca vetorizada)
response = agent.ask(
    "Quais tabelas devo usar para anÃ¡lise de vendas por cliente?"
)

print(response['answer'])
print(f"ConfianÃ§a: {response['confidence']:.1%}")
```

## ğŸ’¡ Casos de Uso

### 1. Descoberta de Dados

**Problema**: Data engineers perdem tempo procurando tabelas relevantes

**SoluÃ§Ã£o**:
```python
# Ao invÃ©s de navegar por centenas de tabelas...
results = agent.search("dados de transaÃ§Ãµes financeiras do Ãºltimo ano")

# ObtÃ©m exatamente o que precisa com contexto
```

### 2. Onboarding de Novos Membros

**Problema**: Novos membros nÃ£o conhecem o data lake

**SoluÃ§Ã£o**:
```python
response = agent.ask(
    "Como funcionam os dados de usuÃ¡rios neste data lake? "
    "Quais tabelas existem e para que servem?"
)
# DocumentaÃ§Ã£o automÃ¡tica e contextual
```

### 3. Compliance e GovernanÃ§a

**Problema**: Identificar todos os dados sensÃ­veis (PII)

**SoluÃ§Ã£o**:
```python
# Busca com filtros
results = agent.search(
    "dados pessoais",
    filter_metadata={"tags": "pii"}
)

# Auditoria facilitada
```

### 4. AnÃ¡lise de Impacto

**Problema**: Entender o impacto de mudanÃ§as em tabelas

**SoluÃ§Ã£o**:
```python
# Combina com Data Lineage Agent
response = agent.ask(
    "Se eu modificar a tabela customers, "
    "quais outras tabelas serÃ£o impactadas?"
)
```

### 5. Data Quality Monitoring

**Problema**: Identificar tabelas que precisam de atenÃ§Ã£o

**SoluÃ§Ã£o**:
```python
results = agent.search(
    "tabelas grandes sem documentaÃ§Ã£o ou com poucos metadados"
)
```

## ğŸ“š Exemplos

### Exemplo 1: Uso BÃ¡sico

```bash
python examples/basic_usage.py
```

Demonstra:
- InicializaÃ§Ã£o do agente
- IndexaÃ§Ã£o de metadados
- Buscas semÃ¢nticas
- Perguntas com RAG

### Exemplo 2: IntegraÃ§Ã£o com Apache Atlas

```bash
python examples/atlas_integration.py
```

Demonstra:
- Import de metadados do Atlas
- ConversÃ£o de entidades Atlas
- Busca em catÃ¡logo corporativo

### Exemplo 3: IntegraÃ§Ã£o com Data Lineage

```bash
python examples/lineage_integration.py
```

Demonstra:
- AnÃ¡lise de linhagem + descoberta
- Contexto enriquecido com dependÃªncias
- AnÃ¡lise de impacto combinada

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Query                           â”‚
â”‚          "Onde estÃ£o os dados de clientes?"            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              OpenAI Embeddings API                      â”‚
â”‚           (text-embedding-3-small)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Vector (1536 dimensions)
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ChromaDB                               â”‚
â”‚            (Vector Database)                            â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Table 1   â”‚  â”‚   Table 2   â”‚  â”‚   Table N   â”‚   â”‚
â”‚  â”‚  Embedding  â”‚  â”‚  Embedding  â”‚  â”‚  Embedding  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Top K Results
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Context Builder                            â”‚
â”‚     (Prepares metadata for LLM)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Context + Query
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 OpenAI LLM                              â”‚
â”‚                 (GPT-5.1)                               â”‚
â”‚        Generates natural language answer               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Response to User                          â”‚
â”‚  "A tabela 'customers' em production.public             â”‚
â”‚   contÃ©m dados de clientes..."                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes

1. **TableMetadata**: Dataclass para metadados estruturados
2. **Embedding Generation**: OpenAI text-embedding-3-small
3. **Vector Database**: ChromaDB com persistÃªncia local
4. **Retrieval**: Busca por similaridade de cosseno
5. **Generation**: GPT-5.1 para respostas contextualizadas

## ğŸ”— IntegraÃ§Ã£o com Apache Atlas

### Exportar do Atlas

```python
from apache_atlas.client.base_client import AtlasClient

# Conecta ao Atlas
client = AtlasClient(
    'http://atlas-host:21000',
    ('admin', 'admin')
)

# Busca tabelas
entities = client.search_entities('hive_table')

# Converte e indexa
from examples.atlas_integration import extract_metadata_from_atlas_entity

for entity in entities:
    table = extract_metadata_from_atlas_entity(entity)
    agent.index_table(table)
```

### Via REST API

```bash
curl -u admin:admin \
  http://atlas-host:21000/api/atlas/v2/search/basic \
  -d '{"typeName": "hive_table"}' \
  -H 'Content-Type: application/json' \
  > atlas_export.json
```

## ğŸ”— IntegraÃ§Ã£o com Data Lineage Agent

```python
from data_lineage_agent import DataLineageAgent
from examples.lineage_integration import convert_lineage_assets_to_metadata

# 1. Analisa linhagem
lineage_agent = DataLineageAgent()
lineage_agent.analyze_pipeline(["pipeline.sql", "etl.py"])

# 2. Converte para metadados RAG
tables = convert_lineage_assets_to_metadata(lineage_agent)

# 3. Indexa com contexto de linhagem
rag_agent.index_tables_batch(tables)

# 4. Busca com contexto de dependÃªncias
results = rag_agent.search("tabelas crÃ­ticas com alto impacto")
```

## ğŸ“– API Reference

### DataDiscoveryRAGAgent

#### `__init__(collection_name, persist_directory, embedding_model, llm_model)`

Inicializa o agente.

**ParÃ¢metros**:
- `collection_name` (str): Nome da coleÃ§Ã£o ChromaDB
- `persist_directory` (str): DiretÃ³rio de persistÃªncia
- `embedding_model` (str): Modelo OpenAI para embeddings
- `llm_model` (str): Modelo OpenAI para geraÃ§Ã£o

#### `index_table(table, force_update=False)`

Indexa uma tabela no banco vetorizado.

**ParÃ¢metros**:
- `table` (TableMetadata): Metadados da tabela
- `force_update` (bool): Atualiza se jÃ¡ existir

#### `index_tables_batch(tables, force_update=False)`

Indexa mÃºltiplas tabelas em batch.

**ParÃ¢metros**:
- `tables` (List[TableMetadata]): Lista de metadados
- `force_update` (bool): Atualiza se jÃ¡ existirem

#### `search(query, n_results=5, filter_metadata=None)`

Busca tabelas usando query natural.

**ParÃ¢metros**:
- `query` (str): Query em linguagem natural
- `n_results` (int): NÃºmero de resultados
- `filter_metadata` (Dict): Filtros de metadados

**Retorna**: `List[SearchResult]`

#### `ask(question, n_context=3, include_reasoning=True)`

Responde pergunta usando RAG.

**ParÃ¢metros**:
- `question` (str): Pergunta em linguagem natural
- `n_context` (int): NÃºmero de tabelas como contexto
- `include_reasoning` (bool): Inclui raciocÃ­nio do LLM

**Retorna**: `Dict` com answer, relevant_tables, confidence

#### `get_statistics()`

Retorna estatÃ­sticas do Ã­ndice.

**Retorna**: `Dict` com total_tables, databases, formats

#### `export_metadata(output_file)`

Exporta metadados para JSON.

#### `import_from_json(json_file)`

Importa metadados de JSON.

#### `reset_index()`

Reseta o Ã­ndice (USE COM CUIDADO!).

## â“ FAQ

### Como funciona a busca semÃ¢ntica?

A busca converte sua query e os metadados em vetores (embeddings) usando o modelo da OpenAI. EntÃ£o, usa similaridade de cosseno para encontrar as tabelas mais relevantes.

### Preciso da OpenAI API?

Sim, atualmente o agente usa OpenAI para embeddings e geraÃ§Ã£o de respostas. VocÃª pode adaptar para usar modelos locais (sentence-transformers) se necessÃ¡rio.

### Quanto custa usar o agente?

Custos tÃ­picos:
- Embedding: ~$0.00002 por 1000 tokens (~$0.02 por 1000 tabelas)
- LLM (perguntas): ~$0.15 por 1M tokens de input

Para 1000 tabelas + 100 perguntas/dia: ~$0.50/dia

### Como lidar com milhares de tabelas?

- Use indexaÃ§Ã£o em batch
- Configure `n_results` apropriadamente
- Use filtros de metadados para refinar buscas
- ChromaDB Ã© otimizado para milhÃµes de vetores

### Como atualizar metadados?

```python
# Re-indexa com force_update=True
agent.index_table(updated_table, force_update=True)
```

### Como integrar com meu catÃ¡logo existente?

Adapte a funÃ§Ã£o `extract_metadata_from_atlas_entity` para seu catÃ¡logo (AWS Glue, Databricks Unity Catalog, etc).

### Como melhorar a qualidade das respostas?

1. **EnriqueÃ§a metadados**: Adicione descriÃ§Ãµes detalhadas
2. **Use tags**: Facilita filtragem e contexto
3. **Ajuste n_context**: Mais contexto = respostas melhores
4. **Atualize embeddings**: Re-indexe quando mudar descriÃ§Ãµes

## ğŸ“ PrÃ³ximos Passos

- [ ] Suporte a modelos locais (sentence-transformers)
- [ ] Interface web para descoberta interativa
- [ ] IntegraÃ§Ã£o com AWS Glue Catalog
- [ ] IntegraÃ§Ã£o com Databricks Unity Catalog
- [ ] Cache de embeddings para reduzir custos
- [ ] Suporte a busca hÃ­brida (keyword + semantic)
- [ ] Fine-tuning de embeddings para domÃ­nio especÃ­fico

## ğŸ“„ LicenÃ§a

Este projeto Ã© parte do Data Governance AI Agents Kit.

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor, abra issues e pull requests.

## ğŸ“§ Suporte

Para dÃºvidas e suporte, abra uma issue no repositÃ³rio.

---

**Desenvolvido com â¤ï¸ usando Claude AI**
