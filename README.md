# Data Governance AI Agents Kit

**Kit completo de agentes de IA para governanÃ§a de dados**, incluindo anÃ¡lise de linhagem e descoberta de dados com RAG.

## ğŸ“‹ VisÃ£o Geral

Este projeto fornece **agentes de IA especializados** para resolver desafios comuns de governanÃ§a de dados:

1. **ğŸ”— Data Lineage Agent**: AnÃ¡lise automÃ¡tica de linhagem de dados
2. **ğŸ” Data Discovery RAG Agent**: Descoberta de dados usando RAG com banco vetorizado
3. **ğŸ›¡ï¸ Data Classification Agent**: ClassificaÃ§Ã£o de PII/PHI/Financeiro a partir de metadados
4. **ğŸ§  Metadata Enrichment Agent**: GeraÃ§Ã£o automÃ¡tica de descriÃ§Ãµes, tags e classificaÃ§Ãµes para ativos de dados

## ğŸš€ Agentes DisponÃ­veis

### 1. Data Lineage Agent

Sistema de IA para **anÃ¡lise automÃ¡tica de linhagem de dados** em pipelines complexos.

**CaracterÃ­sticas**:
- âœ… AnÃ¡lise de mÃºltiplos formatos (Python, SQL, Terraform, Databricks, Airflow)
- âœ… ExtraÃ§Ã£o automÃ¡tica de dependÃªncias
- âœ… VisualizaÃ§Ã£o interativa de grafos
- âœ… AnÃ¡lise de impacto de mudanÃ§as
- âœ… IdentificaÃ§Ã£o de componentes crÃ­ticos
- âœ… IntegraÃ§Ã£o com Apache Atlas

**DocumentaÃ§Ã£o**: [lineage/README.md](lineage/README.md)

**Casos de Uso**:
- Mapeamento de dependÃªncias em pipelines
- AnÃ¡lise de impacto antes de mudanÃ§as
- IdentificaÃ§Ã£o de pontos Ãºnicos de falha
- Auditoria e compliance

**Exemplo RÃ¡pido**:
```python
from lineage.data_lineage_agent import DataLineageAgent

agent = DataLineageAgent()
analysis = agent.analyze_pipeline([
    "etl/extract.sql",
    "etl/transform.py",
    "etl/load.sql"
])

# AnÃ¡lise de impacto
impact = agent.analyze_change_impact(["customers_table"])
print(f"Risk Level: {impact['risk_level']}")
```

---

### 2. Data Discovery RAG Agent

Sistema de IA para **descoberta de dados** usando **RAG (Retrieval-Augmented Generation)** com banco vetorizado.

**CaracterÃ­sticas**:
- âœ… Busca semÃ¢ntica em linguagem natural
- âœ… Banco vetorizado (ChromaDB) para metadados
- âœ… Perguntas e respostas com contexto completo
- âœ… IntegraÃ§Ã£o com Apache Atlas
- âœ… IntegraÃ§Ã£o com Data Lineage Agent
- âœ… Suporte a mÃºltiplos formatos (Parquet, Delta, CSV)

**DocumentaÃ§Ã£o**: [rag_discovery/README.md](rag_discovery/README.md)

**Casos de Uso**:
- Descoberta de dados em data lakes complexos
- Onboarding de novos membros
- IdentificaÃ§Ã£o de dados sensÃ­veis (PII)
- DocumentaÃ§Ã£o automÃ¡tica
- RecomendaÃ§Ã£o de datasets

**Exemplo RÃ¡pido**:
```python
from rag_discovery import DataDiscoveryRAGAgent, TableMetadata

# Inicializa o agente
agent = DataDiscoveryRAGAgent(
    collection_name="my_data_lake"
)

# Indexa uma tabela
table = TableMetadata(
    name="customers",
    database="production",
    description="Dados de clientes",
    columns=[
        {"name": "id", "type": "bigint"},
        {"name": "name", "type": "varchar"}
    ],
    tags=["pii", "critical"]
)
agent.index_table(table)

# Busca semÃ¢ntica
results = agent.search("Onde estÃ£o os dados de clientes?")

# Pergunta com RAG
response = agent.ask(
    "Quais tabelas devo usar para anÃ¡lise de vendas?"
)
print(response['answer'])
```

---

## ğŸ”— IntegraÃ§Ã£o entre Agentes

Os agentes podem ser **integrados** para governanÃ§a completa:

```python
from lineage.data_lineage_agent import DataLineageAgent
from rag_discovery import DataDiscoveryRAGAgent
from metadata_enrichment.agent import MetadataEnrichmentAgent
from rag_discovery.examples.lineage_integration import convert_lineage_assets_to_metadata

# 1. Analisa linhagem
lineage_agent = DataLineageAgent()
lineage_agent.analyze_pipeline(["pipeline.sql", "etl.py"])

# 2. Converte para metadados RAG (com contexto de linhagem)
tables = convert_lineage_assets_to_metadata(lineage_agent)

# 3. Indexa com contexto de dependÃªncias
rag_agent = DataDiscoveryRAGAgent()
rag_agent.index_tables_batch(tables)

# 4. Enriquecimento automÃ¡tico de metadados
enrichment_agent = MetadataEnrichmentAgent(...)
enriched_tables = [
    enrichment_agent.enrich_from_sql(table.name, connection_string="...")
    for table in tables
]

# 5. ClassificaÃ§Ã£o de sensibilidade (usando schemas enriquecidos)
# ... montar TableSchema a partir dos metadados e usar DataClassificationAgent

# 6. Busca considerando impacto e sensibilidade
results = rag_agent.search("tabelas crÃ­ticas com PII e alto impacto downstream")

# 7. AnÃ¡lise de impacto enriquecida
response = rag_agent.ask("Se eu modificar a tabela customers, qual o impacto?")
```

**BenefÃ­cios da IntegraÃ§Ã£o**:
- ğŸ¯ Descoberta de dados com contexto de linhagem
- ğŸ“Š AnÃ¡lise de impacto enriquecida com IA
- ğŸ” Busca semÃ¢ntica considerando dependÃªncias e sensibilidade
- ğŸ“ DocumentaÃ§Ã£o automÃ¡tica e enriquecimento de catÃ¡logos

---

### 3. Data Classification Agent

Agente para **classificar automaticamente dados sensÃ­veis (PII, PHI e financeiros)** usando apenas schemas e metadados, garantindo alinhamento com **LGPD/GDPR** sem acessar os dados brutos.

**CaracterÃ­sticas**:
- âœ… IdentificaÃ§Ã£o de PII/PHI/Financeiro via nomes, tipos, descriÃ§Ãµes e tags
- âœ… NÃ­veis de severidade (LOW, MEDIUM, HIGH, CRITICAL)
- âœ… RecomendaÃ§Ãµes de compliance (DPIA, minimizaÃ§Ã£o, mascaramento/tokenizaÃ§Ã£o)
- âœ… ExtensÃ­vel com regras customizadas (`SensitiveDataRule`)

**DocumentaÃ§Ã£o**: [classification/README.md](classification/README.md)

**Exemplo RÃ¡pido**:
```python
from classification import (
    ColumnMetadata,
    DataClassificationAgent,
    TableSchema,
)

table = TableSchema(
    name="payments",
    schema="finance",
    description="TransaÃ§Ãµes com cartÃ£o e CPF do pagador",
    columns=[
        ColumnMetadata(name="payment_id", type="bigint"),
        ColumnMetadata(name="cpf", type="varchar", tags=["pii"]),
        ColumnMetadata(name="credit_card_number", type="varchar"),
    ],
)

agent = DataClassificationAgent()
classification = agent.classify_table(table)
print(classification.sensitivity_level)  # HIGH
print(classification.detected_categories)  # ['FINANCIAL', 'PII']
```

---

### 4. Metadata Enrichment Agent

Agente de IA para **gerar descriÃ§Ãµes, tags, classificaÃ§Ã£o e detecÃ§Ã£o de PII** a partir de schemas, amostras de dados e normativos.

**CaracterÃ­sticas**:
- âœ… GeraÃ§Ã£o automÃ¡tica de descriÃ§Ãµes PT/EN para tabelas e colunas
- âœ… ClassificaÃ§Ã£o de dados (public, internal, confidential, restricted) com detecÃ§Ã£o de PII
- âœ… SugestÃ£o de domÃ­nio e proprietÃ¡rio, alÃ©m de tags de organizaÃ§Ã£o
- âœ… RAG sobre normativos internos (nomenclatura, governanÃ§a, seguranÃ§a)
- âœ… Data sampling para CSV, Parquet, SQL e Delta Lake
- âœ… ExportaÃ§Ã£o em JSON, Markdown e HTML

**DocumentaÃ§Ã£o**: [metadata_enrichment/README.md](metadata_enrichment/README.md)

**Casos de Uso**:
- DocumentaÃ§Ã£o automÃ¡tica de tabelas de data lakes/warehouses
- CriaÃ§Ã£o rÃ¡pida de catÃ¡logos de dados com sugestÃµes consistentes
- Enriquecimento de metadados para onboarding e descoberta
- PadronizaÃ§Ã£o baseada em normativos internos

**Exemplo RÃ¡pido**:
```python
from metadata_enrichment.agent import MetadataEnrichmentAgent
from rag_discovery.providers.embeddings import SentenceTransformerEmbeddings
from rag_discovery.providers.llm import OpenAILLM
from rag_discovery.providers.vectorstore import ChromaStore

agent = MetadataEnrichmentAgent(
    embedding_provider=SentenceTransformerEmbeddings(),
    llm_provider=OpenAILLM(model="gpt-4o-mini"),
    vector_store=ChromaStore(collection_name="standards")
)

agent.index_standards_from_json("./examples/sample_standards.json")
result = agent.enrich_from_csv("./data/customers.csv")

print(result.classification)  # ex.: confidential
print(result.has_pii)
```

---

## ğŸ“¦ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8+
- OpenAI API Key (para RAG Agent)

### InstalaÃ§Ã£o Completa

```bash
# Clone o repositÃ³rio
git clone <repo-url>
cd data-governance-ai-agents-kit

# Instale todas as dependÃªncias da UI + agentes usando o MESMO Python do Streamlit
python -m pip install -r requirements.txt

# Configure variÃ¡veis de ambiente
export OPENAI_API_KEY="sua-chave-aqui"
```

> Se ainda aparecer `ModuleNotFoundError: No module named 'openai'`, confirme que o
> `python -m pip` acima corresponde ao Python que executarÃ¡ `streamlit run app.py`.
> VocÃª pode verificar com `python -V` e `python -m pip -V`.

### InstalaÃ§Ã£o Individual

**Apenas Lineage Agent**:
```bash
pip install -r lineage/requirements.txt
```

**Apenas RAG Agent**:
```bash
pip install -r rag_discovery/requirements.txt
export OPENAI_API_KEY="sua-chave-aqui"
```

**Apenas Data Classification Agent**:
```bash
pip install -r classification/requirements.txt
```

**Apenas Metadata Enrichment Agent**:
```bash
pip install -r metadata_enrichment/requirements.txt
export OPENAI_API_KEY="sua-chave-aqui"
```

---

## ğŸ¯ Casos de Uso Combinados

### 1. GovernanÃ§a Completa de Data Lake

**CenÃ¡rio**: Empresa precisa de visibilidade completa do data lake

**SoluÃ§Ã£o**:
1. Use **Lineage Agent** para mapear dependÃªncias
2. Use **Metadata Enrichment Agent** para gerar descriÃ§Ãµes e classificaÃ§Ã£o
3. Use **Classification Agent** para confirmar sensibilidade
4. Use **RAG Agent** para descoberta semÃ¢ntica com contexto completo
5. Combine para anÃ¡lise de impacto contextualizada

### 2. MigraÃ§Ã£o de Plataforma

**CenÃ¡rio**: MigraÃ§Ã£o de on-premise para cloud

**SoluÃ§Ã£o**:
1. **Lineage Agent** identifica todas as dependÃªncias
2. **RAG Agent** documenta e organiza metadados
3. AnÃ¡lise de impacto previne quebras

### 3. Compliance e Auditoria

**CenÃ¡rio**: Atender LGPD/GDPR

**SoluÃ§Ã£o**:
1. **Metadata Enrichment Agent** sugere domÃ­nios, donos e detecta PII
2. **Classification Agent** consolida nÃ­veis de sensibilidade e controles
3. **Lineage Agent** rastreia fluxo de dados sensÃ­veis
4. **RAG Agent** facilita buscas contextualizadas para auditoria

### 4. Onboarding de Equipe

**CenÃ¡rio**: Novos data engineers precisam entender o data lake

**SoluÃ§Ã£o**:
1. **RAG Agent** responde perguntas em linguagem natural
2. **Lineage Agent** mostra dependÃªncias visualmente
3. DocumentaÃ§Ã£o contextualizada automÃ¡tica

---

## ğŸ“š Exemplos

### Lineage Agent

```bash
# Exemplo bÃ¡sico
cd lineage
python examples/basic_usage.py

# AnÃ¡lise de impacto
python examples/impact_analysis.py

# VisualizaÃ§Ã£o Atlas
python examples/atlas_visualization.py
```

### RAG Agent

```bash
# Exemplo bÃ¡sico
cd rag_discovery
python examples/basic_usage.py

# IntegraÃ§Ã£o com Atlas
python examples/atlas_integration.py

# IntegraÃ§Ã£o com Lineage
python examples/lineage_integration.py
```

---

## ğŸ—ï¸ Arquitetura

```
data-governance-ai-agents-kit/
â”‚
â”œâ”€â”€ lineage/                          # Data Lineage Agent
â”‚   â”œâ”€â”€ data_lineage_agent.py         # Agente principal
â”‚   â”œâ”€â”€ parsers/                      # Parsers (SQL, Python, etc)
â”‚   â”œâ”€â”€ examples/                     # Exemplos de uso
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ rag_discovery/                    # Data Discovery RAG Agent
â”‚   â”œâ”€â”€ data_discovery_rag_agent.py   # Agente principal
â”‚   â”œâ”€â”€ examples/                     # Exemplos de uso
â”‚   â”‚   â”œâ”€â”€ basic_usage.py
â”‚   â”‚   â”œâ”€â”€ atlas_integration.py
â”‚   â”‚   â””â”€â”€ lineage_integration.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ .gitignore
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ classification/                   # Data Classification Agent
â”‚   â”œâ”€â”€ data_classification_agent.py  # Agente principal
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ metadata_enrichment/              # Metadata Enrichment Agent
â”‚   â”œâ”€â”€ agent.py                      # Agente principal
â”‚   â”œâ”€â”€ standards/                    # RAG para normativos
â”‚   â”œâ”€â”€ sampling/                     # Coletores de amostras de dados
â”‚   â”œâ”€â”€ examples/                     # Exemplos e normativos
â”‚   â”œâ”€â”€ streamlit_app.py              # UI dedicada
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ README.md                         # Este arquivo
```

---

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

```bash
# OpenAI (para RAG Agent)
export OPENAI_API_KEY="sk-..."
export OPENAI_API_URL="https://api.openai.com/v1"  # Opcional

# Data Lineage LLM (opcional - para fallback parsing)
export DATA_LINEAGE_LLM_MODEL="gpt-5.1"

# Apache Atlas (opcional)
export ATLAS_HOST="http://atlas-host:21000"
export ATLAS_USERNAME="admin"
export ATLAS_PASSWORD="admin"
```

---

## ğŸ“Š ComparaÃ§Ã£o de Agentes

| CaracterÃ­stica | Lineage Agent | RAG Agent | Classification Agent | Metadata Enrichment Agent |
|---------------|---------------|-----------|----------------------|---------------------------|
| **Objetivo** | Mapear dependÃªncias | Descobrir dados | Classificar PII/PHI/Financeiro | Enriquecer descriÃ§Ãµes, tags e classificaÃ§Ã£o |
| **Input** | CÃ³digo (SQL, Python) | Metadados | Schemas e metadados | Schemas, amostras e normativos |
| **Output** | Grafo de linhagem | Respostas em LN | NÃ­vel de sensibilidade e controles | DescriÃ§Ãµes PT/EN, tags, classificaÃ§Ã£o |
| **TÃ©cnica** | AST parsing + Graph | Embeddings + RAG | Regras semÃ¢nticas + (opcional) LLM | RAG sobre normativos + sampling |
| **LLM** | Opcional (fallback) | Requerido | Opcional (validaÃ§Ã£o) | Recomendado |
| **Casos de Uso** | AnÃ¡lise de impacto | Busca semÃ¢ntica | Compliance LGPD/GDPR | CatÃ¡logo e documentaÃ§Ã£o automÃ¡tica |

---

## ğŸ›£ï¸ Roadmap

### Lineage Agent
- [x] Parsers bÃ¡sicos (SQL, Python, Terraform)
- [x] VisualizaÃ§Ã£o de grafos
- [x] AnÃ¡lise de impacto
- [x] IntegraÃ§Ã£o com Apache Atlas
- [ ] Suporte a dbt
- [ ] Suporte a Airflow nativo
- [ ] Column-level lineage

### RAG Agent
- [x] Busca semÃ¢ntica bÃ¡sica
- [x] IntegraÃ§Ã£o com Atlas
- [x] IntegraÃ§Ã£o com Lineage Agent
- [ ] Suporte a modelos locais (sentence-transformers)
- [ ] Interface web interativa
- [ ] IntegraÃ§Ã£o com AWS Glue
- [ ] IntegraÃ§Ã£o com Databricks Unity Catalog
- [ ] Cache de embeddings

### Classification Agent
- [x] Regras de PII/PHI/Financeiro baseadas em metadados
- [x] NÃ­veis de severidade e recomendaÃ§Ãµes LGPD/GDPR
- [ ] ValidaÃ§Ã£o multilÃ­ngue com LLM
- [ ] Biblioteca ampliada de regras setoriais

### Metadata Enrichment Agent
- [x] RAG sobre normativos internos
- [x] Suporte a sampling (CSV, Parquet, SQL, Delta)
- [x] ExportaÃ§Ã£o em JSON/Markdown/HTML
- [ ] Conectores adicionais (BigQuery, S3 inventories)
- [ ] Templates personalizÃ¡veis de catÃ¡logo

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/amazing-feature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add amazing feature'`)
4. Push para a branch (`git push origin feature/amazing-feature`)
5. Abra um Pull Request

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a licenÃ§a MIT - veja o arquivo LICENSE para detalhes.

---

## ğŸ“§ Suporte

Para dÃºvidas, sugestÃµes ou suporte:

- ğŸ› **Issues**: Abra uma issue no GitHub
- ğŸ’¬ **DiscussÃµes**: Use a seÃ§Ã£o de Discussions
- ğŸ“§ **Email**: [seu-email]

---

## ğŸ™ Agradecimentos

- **Apache Atlas** - IntegraÃ§Ã£o de catÃ¡logo
- **ChromaDB** - Banco vetorizado
- **OpenAI** - Embeddings e LLM
- **NetworkX** - AnÃ¡lise de grafos
- **Plotly** - VisualizaÃ§Ãµes interativas

---

## â­ Star History

Se este projeto foi Ãºtil para vocÃª, considere dar uma â­!

---
